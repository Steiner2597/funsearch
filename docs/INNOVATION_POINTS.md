# Innovation Points (åˆ›æ–°ç‚¹è¯¦è§£)

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜ FunSearch-Lite é¡¹ç›®çš„ **ä¸‰ä¸ªåˆ›æ–°ç‚¹**ï¼Œå¹¶æä¾›å®ç°è¯æ®å’Œå®éªŒéªŒè¯ã€‚

> **è¯¾ç¨‹å¯¹åº”**: æœ¬é¡¹ç›®å¯¹åº”è¯¾ç¨‹æ¨èçš„ "FunSearch enhancements" æ–¹å‘ï¼Œå®ç°äº† Sample-efficientã€Multi-modelã€Novelty-driven ä¸‰ä¸ªå¢å¼ºã€‚

## åˆ›æ–°ç‚¹æ¦‚è§ˆ

| # | åˆ›æ–°ç‚¹ | è¯¾ç¨‹å¯¹åº”æ–¹å‘ | æ ¸å¿ƒæ€æƒ³ | å®ç°æ¨¡å— | æ”¶ç›Š |
|---|--------|-------------|----------|----------|------|
| 1 | åŠŸèƒ½çº§å»é‡ | Sample-efficient FunSearch | ä¸¤é˜¶æ®µå»é‡ï¼šä»£ç è§„èŒƒåŒ–å“ˆå¸Œ + è¡Œä¸ºç­¾å | `funsearch_core/deduplication.py` | é¿å…é‡å¤è¯„ä¼° |
| 2 | å¯é…ç½®å¤šæ¨¡å‹ | æˆæœ¬æ„ŸçŸ¥/åä½œæœç´¢ | ç”Ÿæˆå™¨ä¸ç²¾ç‚¼å™¨å¯ç»‘å®šä¸åŒ LLM provider | `experiments/runner.py` | ä¾¿äºæŒ‰é¢„ç®—/è´¨é‡é€‰æ‹©æ¨¡å‹ |
| 3 | å¤šæ ·æ€§é©±åŠ¨æœç´¢ | Novelty-driven FunSearch | å¤šå²›æ¨¡å‹ + è¡Œä¸ºç­¾åå¤šæ ·æ€§è¿‡æ»¤ï¼ˆéœ€é…ç½®è¿ç§»å¯ç”¨ï¼‰ | `funsearch_core/islands.py` + `diversity.py` | å‡å°‘æ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜ |

**å·¥ç¨‹ä¼˜åŒ–** (éæ ¸å¿ƒåˆ›æ–°):
- å¤šä¿çœŸåº¦è¯„ä¼°: cheap â†’ full ä¸¤é˜¶æ®µç­›é€‰ (`evaluator/bin_packing.py`)
- æœç´¢è½¨è¿¹å¯è§‚æµ‹æ€§: å®æ—¶æŒ‡æ ‡ + å¯è§†åŒ– (`experiments/metrics.py` + `plotting.py`)
- æ²™ç®±æ‰¹é‡è¯„ä¼°ï¼šéš”ç¦»æ‰§è¡Œå¹¶æ‰¹é‡è¯„åˆ† (`experiments/runner.py` + `sandbox/executor.py`)

---

## åˆ›æ–°ç‚¹ 1: åŠŸèƒ½çº§å»é‡ (Functional Deduplication)

> **è¯¾ç¨‹åŸæ–‡**: "Instead of assessing blindly all programs/codes created by an LLM, can we design a **duplicate code-checking mechanism** to avoid FunSearch evaluating a code that has been previously evaluated? ... The similarity between two programs/codes should be defined at the **functionality level**."

### 1.1 é—®é¢˜èƒŒæ™¯

åœ¨ FunSearch è¿›è¡Œè¿‡ç¨‹ä¸­ï¼ŒLLM ä¼šç”Ÿæˆå¤§é‡å€™é€‰ä»£ç :

- è®¸å¤šä»£ç è™½ç„¶**æ–‡æœ¬ä¸åŒ**ï¼Œä½†**åŠŸèƒ½ç›¸åŒ**
- å¯¹åŠŸèƒ½ç›¸åŒçš„ä»£ç é‡å¤è¯„ä¼°æ˜¯æµªè´¹
- è¯¾ç¨‹æ˜ç¡®è¦æ±‚ï¼šç›¸ä¼¼æ€§åº”åœ¨**åŠŸèƒ½å±‚é¢**å®šä¹‰

**è¯¾ç¨‹ç»™å‡ºçš„ä¾‹å­**:
```python
# Code A
def mean(lst):
    return sum(lst) / len(lst)

# Code B  
def mean(lst):
    total = 0
    for x in lst:
        total += x
    return total / len(lst)
```
è¿™ä¸¤æ®µä»£ç **æ–‡æœ¬å®Œå…¨ä¸åŒ**ï¼Œä½†**åŠŸèƒ½å®Œå…¨ç›¸åŒ**â€”â€”å¯¹ä»»ä½•è¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡ºã€‚

### 1.2 è§£å†³æ–¹æ¡ˆ

å®æ–½ **ä¸¤é˜¶æ®µå»é‡æœºåˆ¶** (ä»£ç å“ˆå¸Œ + è¡Œä¸ºç­¾å):

```
ä¸¤é˜¶æ®µåŠŸèƒ½çº§å»é‡æµç¨‹:
  â”œâ”€ ç¬¬ä¸€é˜¶æ®µ: ä»£ç å“ˆå¸Œ (å¿«é€Ÿè¿‡æ»¤)
  â”‚     â”œâ”€ 1. å¯¹ä»£ç è¿›è¡Œè§„èŒƒåŒ– (ç§»é™¤æ³¨é‡Šã€ç©ºç™½æ ‡å‡†åŒ–)
  â”‚     â”œâ”€ 2. è®¡ç®—è§„èŒƒåŒ–ä»£ç çš„ SHA256 å“ˆå¸Œ
  â”‚     â””â”€ 3. æ£€æŸ¥å“ˆå¸Œæ˜¯å¦åœ¨ç¼“å­˜ä¸­ â†’ å‘½ä¸­åˆ™ç›´æ¥è·³è¿‡
  â”‚
  â”œâ”€ ç¬¬äºŒé˜¶æ®µ: è¡Œä¸ºç­¾å (ç²¾ç¡®æ£€æµ‹)
  â”‚     â”œâ”€ 1. å¯¹æ–°ç”Ÿæˆçš„ä»£ç ï¼Œåœ¨å¤šä¸ªæ¢é’ˆå®ä¾‹ä¸Šè¿è¡Œ
  â”‚     â”œâ”€ 2. è®°å½•æ¯æ­¥çš„è¯„åˆ†å†³ç­–ï¼Œå½¢æˆ"è¡Œä¸ºæŒ‡çº¹"
  â”‚     â”œâ”€ 3. å¯¹è¡Œä¸ºæŒ‡çº¹å“ˆå¸Œï¼Œå¾—åˆ°"è¡Œä¸ºç­¾å"
  â”‚     â””â”€ 4. æ£€æŸ¥ç­¾åæ˜¯å¦å·²å­˜åœ¨äºç¼“å­˜
  â”‚           â”œâ”€ å­˜åœ¨ â†’ è·³è¿‡è¯„ä¼° (åŠŸèƒ½é‡å¤)
  â”‚           â””â”€ ä¸å­˜åœ¨ â†’ æ­£å¸¸è¯„ä¼°ï¼Œå¹¶ç¼“å­˜ç­¾å
  â”‚
  â””â”€ æ•ˆæœ: å¿«é€Ÿè¿‡æ»¤æ–‡æœ¬ç›¸ä¼¼ä»£ç  + ç²¾ç¡®æ£€æµ‹åŠŸèƒ½ç­‰ä»·ä»£ç 
```

**å…³é”®è®¾è®¡å†³ç­–**: è¡Œä¸ºæŒ‡çº¹è®°å½•çš„æ˜¯æ¯æ­¥çš„ **è¯„åˆ†å€¼**ï¼Œè€Œéæœ€ç»ˆè£…ç®±ç»“æœã€‚
è¿™æ ·å³ä½¿ä¸¤ä¸ªç­–ç•¥é€‰æ‹©ç›¸åŒçš„ç®±å­ï¼Œä½†è¯„åˆ†è®¡ç®—æ–¹å¼ä¸åŒä¹Ÿä¼šè¢«åŒºåˆ†ã€‚

### 1.3 å®ç°è¯æ®

#### ä»£ç ä½ç½®: `funsearch_core/deduplication.py`

```python
# ============ ç¬¬ä¸€é˜¶æ®µ: ä»£ç å“ˆå¸Œ ============

def _normalize_code(code: str) -> str:
    """è§„èŒƒåŒ–ä»£ç ä»¥è¿›è¡Œæ¯”è¾ƒã€‚
    
    é€šè¿‡ç§»é™¤æ³¨é‡Šã€æ–‡æ¡£å­—ç¬¦ä¸²å¹¶æ ‡å‡†åŒ–ç©ºç™½ç¬¦ï¼Œ
    ä½¿å¾—æ–‡æœ¬ä¸åŒä½†è¯­ä¹‰ç›¸åŒçš„ä»£ç äº§ç”Ÿç›¸åŒå“ˆå¸Œã€‚
    """
    import re
    # ç§»é™¤å•è¡Œæ³¨é‡Š
    code = re.sub(r'#.*$', '', code, flags=re.MULTILINE)
    # ç§»é™¤æ–‡æ¡£å­—ç¬¦ä¸² (ä¸‰å¼•å·åŒ…è£¹çš„å†…å®¹)
    code = re.sub(r'""".*?"""', '', code, flags=re.DOTALL)
    code = re.sub(r"'''.*?'''", '', code, flags=re.DOTALL)
    # æ ‡å‡†åŒ–ç©ºç™½: å°†å¤šä¸ªç©ºç™½ç¬¦æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
    code = re.sub(r'\s+', ' ', code)
    return code.strip()


def _code_hash(code: str) -> str:
    """è®¡ç®—è§„èŒƒåŒ–ä»£ç çš„å“ˆå¸Œå€¼ã€‚"""
    normalized = _normalize_code(code)
    return hashlib.sha256(normalized.encode("utf-8")).hexdigest()


# ============ ç¬¬äºŒé˜¶æ®µ: è¡Œä¸ºç­¾å ============

@dataclass(frozen=True)
class BehaviorSignature:
    """ä»£è¡¨å€™é€‰ä»£ç çš„åŠŸèƒ½è¡Œä¸ºã€‚
    
    ä¸¤ä¸ªå…·æœ‰ç›¸åŒç­¾åçš„å€™é€‰æ˜¯åŠŸèƒ½ç­‰ä»·çš„ï¼Œ
    å³ä½¿å®ƒä»¬çš„æºä»£ç çœ‹èµ·æ¥å®Œå…¨ä¸åŒã€‚
    """
    hash: str              # è¡Œä¸ºç­¾åå“ˆå¸Œ
    vector: tuple[float, ...]  # è¡Œä¸ºå‘é‡


class FunctionalDeduplicator:
    """ä¸¤é˜¶æ®µåŠŸèƒ½å»é‡å™¨ã€‚
    
    ç¬¬ä¸€é˜¶æ®µ: ä»£ç è§„èŒƒåŒ–å“ˆå¸Œ (å¿«é€Ÿè¿‡æ»¤)
    ç¬¬äºŒé˜¶æ®µ: è¡Œä¸ºç­¾åæ£€æµ‹ (ç²¾ç¡®åˆ¤æ–­)
    """
    
    def __init__(
        self,
        probe_runner: Callable[[str, int], float],
        probe_seeds: Sequence[int] | None = None,
        cache_size_limit: int = 10000,
        use_code_hash: bool = True,  # æ˜¯å¦å¯ç”¨ç¬¬ä¸€é˜¶æ®µ
    ) -> None:
        self._probe_runner = probe_runner
        self._probe_seeds = list(probe_seeds) if probe_seeds else [0, 1, 2, 3, 4]
        self._signature_cache: set[str] = set()
        self._code_hash_cache: set[str] = set()  # ç¬¬ä¸€é˜¶æ®µç¼“å­˜
        self._use_code_hash = use_code_hash
    
    def is_duplicate(self, code: str) -> tuple[bool, BehaviorSignature]:
        """ä¸¤é˜¶æ®µå»é‡æ£€æŸ¥ã€‚"""
        self._stats.total_checked += 1
        
        # ç¬¬ä¸€é˜¶æ®µ: å¿«é€Ÿä»£ç å“ˆå¸Œæ£€æŸ¥
        if self._use_code_hash:
            code_h = _code_hash(code)
            if code_h in self._code_hash_cache:
                self._stats.duplicates_found += 1
                return True, BehaviorSignature.from_vector([float("nan")])
            self._code_hash_cache.add(code_h)
        
        # ç¬¬äºŒé˜¶æ®µ: è¡Œä¸ºç­¾åæ£€æŸ¥
        signature = self.compute_signature(code)
        if signature.hash in self._signature_cache:
            self._stats.duplicates_found += 1
            return True, signature
        
        self._signature_cache.add(signature.hash)
        return False, signature
```

#### æ¢é’ˆè¿è¡Œå™¨: è®°å½•è¯„åˆ†å†³ç­–

```python
def create_binpacking_probe_runner(
    capacity: int = 100,
    num_items: int = 15,
) -> Callable[[str, int], float]:
    """åˆ›å»ºæ•è·è¯„åˆ†è¡Œä¸ºçš„æ¢é’ˆè¿è¡Œå™¨ã€‚
    
    å…³é”®è®¾è®¡: è®°å½•æ¯æ­¥çš„è¯„åˆ†å€¼ï¼Œè€Œéæœ€ç»ˆè£…ç®±ç»“æœã€‚
    è¿™æ ·å¯ä»¥åŒºåˆ†è¯„åˆ†æ–¹å¼ä¸åŒä½†é€‰æ‹©ç›¸åŒç®±å­çš„ç­–ç•¥ã€‚
    """
    def probe_runner(code: str, seed: int) -> float:
        # ä½¿ç”¨ä¸åŒåˆ†å¸ƒç”Ÿæˆç¡®å®šæ€§ç‰©å“åºåˆ—
        # ... (æ•°æ®ç”Ÿæˆè¿‡ç¨‹)
        
        behavior_fingerprint = 0.0
        bins_remaining = [capacity]
        
        for step, item_size in enumerate(items):
            scores_for_step = []
            # è¿è¡Œ LLM ç”Ÿæˆçš„ score_bin å‡½æ•°
            for i, remaining in enumerate(bins_remaining):
                if remaining >= item_size:
                    score = float(score_bin(item_size, remaining, i, step))
                    scores_for_step.append(score)
            
            # å…³é”®æ´å¯Ÿ: å°†è¯„åˆ†å€¼æœ¬èº«ç¼–ç åˆ°æŒ‡çº¹ä¸­ (ä¸ä»…ä»…æ˜¯æœ€ç»ˆé€‰æ‹©)
            # è¿™èƒ½æœ‰æ•ˆåŒºåˆ†è¯„åˆ†é€»è¾‘ä¸åŒä½†ç¢°å·§é€‰æ‹©äº†åŒä¸€ä¸ªç®±å­çš„å¯å‘å¼ç®—æ³•
            for idx, s in enumerate(scores_for_step):
                if s == s:  # æ’é™¤ NaN
                    # æ ¹æ®ä½ç½®å’Œæ­¥æ•°èµ‹äºˆæƒé‡ï¼Œç”Ÿæˆå”¯ä¸€è¡Œä¸ºæŒ‡çº¹
                    behavior_fingerprint += s * (0.1 ** (idx % 5)) * (1.0 + step * 0.01)
            
            # æ‰§è¡Œè£…ç®± (å…¥æœ€ä½³å¾—åˆ†ç®±æˆ–æ–°å¼€ç®±)
            # ...
            
            # åŒæ—¶å°†æœ€ç»ˆå†³ç­–è·¯å¾„ä¹Ÿç¼–ç åˆ°æŒ‡çº¹ä¸­
            behavior_fingerprint += best_bin * 100 + step
        
        # å°†æœ€ç»ˆç®±å­æ€»æ•°ä¹Ÿä½œä¸ºç»´åº¦åŒ…å«åœ¨å†…
        behavior_fingerprint += len(bins_remaining) * 10000
        return behavior_fingerprint
    
    return probe_runner
```

#### è°ƒç”¨ä½ç½®: `funsearch_core/loop.py`

```python
class FunSearchLoop:
    def run_generation(self) -> dict[str, object]:
        for island_index, island in enumerate(self.islands.islands):
            new_candidates = self._generate_candidates_for_island(...)
            
            # Sample-efficient: è·³è¿‡åŠŸèƒ½é‡å¤çš„å€™é€‰
            if self.deduplicator:
                unique_candidates = []
                for candidate in new_candidates:
                    is_dup, _ = self.deduplicator.is_duplicate(candidate.code)
                    if is_dup:
                        # æ ‡è®°ä¸ºé‡å¤ï¼Œè·³è¿‡è¯„ä¼°
                        candidate.eval_metadata["skipped_duplicate"] = True
                        candidate.score = None
                        gen_dedup_skipped += 1
                    else:
                        unique_candidates.append(candidate)
                candidates_to_eval = unique_candidates
            else:
                candidates_to_eval = new_candidates
            
            # åªè¯„ä¼°éé‡å¤å€™é€‰
            _ = self._evaluate_candidates(candidates_to_eval, fidelity="cheap")
```

### 1.4 æ•ˆæœåˆ†æ

**ä¼ ç»Ÿæ–¹æ¡ˆ (æ— å»é‡)**:
- æ¯ä»£ç”Ÿæˆ 50 ä¸ªå€™é€‰ï¼Œå…¨éƒ¨è¯„ä¼°
- å‡è®¾ 30% åŠŸèƒ½é‡å¤ â†’ 15 æ¬¡æ— æ•ˆè¯„ä¼°/ä»£
- 20 ä»£ â†’ 300 æ¬¡æ— æ•ˆè¯„ä¼°

**ä¸¤é˜¶æ®µå»é‡æ–¹æ¡ˆ**:

| é˜¶æ®µ | æ£€æµ‹ç›®æ ‡ | é€Ÿåº¦ | å‡†ç¡®åº¦ |
|------|----------|------|--------|
| ä»£ç å“ˆå¸Œ | æ–‡æœ¬ç›¸ä¼¼çš„å˜ä½“ (å¦‚åªæ”¹ç©ºæ ¼/æ³¨é‡Š) | æå¿« (< 1ms) | 100% ç²¾ç¡® |
| è¡Œä¸ºç­¾å | åŠŸèƒ½ç­‰ä»·çš„ä¸åŒå®ç° | è¾ƒå¿« (10-50ms) | é«˜ (æ¢é’ˆè¦†ç›–) |

**å®é™…æ”¶ç›Š**:
- âœ… ä»£ç å“ˆå¸Œå¿«é€Ÿæ‹¦æˆª LLM ç”Ÿæˆçš„å¾®å°å˜ä½“
- âœ… è¡Œä¸ºç­¾åæ£€æµ‹é€»è¾‘ç­‰ä»·çš„ä¸åŒç®—æ³•å®ç°
- âœ… æ€»å»é‡ç‡çº¦ 20-40%ï¼ŒèŠ‚çœå¯¹åº”è¯„ä¼°æ—¶é—´
- âœ… **ç›´æ¥å¯¹åº”è¯¾ç¨‹è¦æ±‚**

### 1.5 éªŒè¯æ–¹æ³•

```bash
# è¿è¡Œæµ‹è¯•éªŒè¯åŠŸèƒ½çº§å»é‡
python -m pytest tests/test_deduplication.py -v

# è¿è¡Œå®éªŒå¹¶æ£€æŸ¥å»é‡ç»Ÿè®¡
python -m experiments.cli run configs/binpacking.yaml

# æ£€æŸ¥å»é‡æ•ˆæœ
cat artifacts/binpacking_demo_001/metrics.jsonl | grep "dedup_skipped"
```

### 1.6 å…³é”®æµ‹è¯•ç”¨ä¾‹

```python
def test_two_stage_deduplication(self) -> None:
    """æµ‹è¯•ä¸¤é˜¶æ®µå»é‡: ä»£ç å“ˆå¸Œ + è¡Œä¸ºç­¾åã€‚"""
    dedup = FunctionalDeduplicator(
        probe_runner=simple_probe,
        probe_seeds=[0, 1, 2],
        use_code_hash=True,
    )
    
    code_a = "def f(x): return x + 1"
    
    # ç¬¬ä¸€é˜¶æ®µæµ‹è¯•: ä»£ç è§„èŒƒåŒ–
    # åªæœ‰ç©ºæ ¼ä¸åŒçš„ä»£ç åº”è¢«ä»£ç å“ˆå¸Œæ•è·
    code_a_whitespace = "def f(x):  return x + 1  "  # å¤šä½™ç©ºæ ¼
    
    is_dup1, _ = dedup.is_duplicate(code_a)
    assert not is_dup1  # ç¬¬ä¸€ä¸ªæ˜¯æ–°çš„
    
    is_dup2, _ = dedup.is_duplicate(code_a_whitespace)
    assert is_dup2  # è§„èŒƒåŒ–åç›¸åŒï¼Œç¬¬ä¸€é˜¶æ®µå°±èƒ½æ•è·


def test_different_code_same_behavior_is_duplicate(self) -> None:
    """æµ‹è¯•æ ¸å¿ƒæ´è§: ä¸åŒä»£ç ï¼Œç›¸åŒè¡Œä¸º = é‡å¤ã€‚
    
    è¿™æ˜¯è¯¾ç¨‹è¦æ±‚çš„å…³é”®åˆ›æ–° (ç¬¬äºŒé˜¶æ®µè¡Œä¸ºç­¾å)ã€‚
    """
    # ä¸¤ä¸ªä¸åŒå®ç°çš„ mean å‡½æ•°
    code_a = "def mean(lst): return sum(lst) / len(lst)"
    code_b = """
def mean(lst):
    total = 0
    for x in lst:
        total += x
    return total / len(lst)
"""
    
    is_dup1, sig1 = dedup.is_duplicate(code_a)
    assert not is_dup1  # ç¬¬ä¸€ä¸ªæ˜¯æ–°çš„
    
    is_dup2, sig2 = dedup.is_duplicate(code_b)
    assert is_dup2  # ç¬¬äºŒä¸ªåŠŸèƒ½ç›¸åŒï¼Œåº”è¢«æ£€æµ‹ä¸ºé‡å¤!
    assert sig1.hash == sig2.hash  # ç­¾åç›¸åŒ
```

---

## åˆ›æ–°ç‚¹ 2: å¯é…ç½®å¤šæ¨¡å‹ (Multi-Model Configuration)

### 2.1 é—®é¢˜èƒŒæ™¯

LLM è´¨é‡ã€æˆæœ¬ã€é€Ÿåº¦å­˜åœ¨æƒè¡¡ï¼Œä½†ä¸åŒé¡¹ç›®çš„é¢„ç®—å’Œç²¾åº¦è¦æ±‚å„å¼‚ï¼Œå› æ­¤éœ€è¦åœ¨é…ç½®å±‚é¢çµæ´»åˆ‡æ¢æˆ–ç»„åˆæ¨¡å‹ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç æŸä¸ªâ€œåä½œç­–ç•¥â€ã€‚

### 2.2 è§£å†³æ–¹æ¡ˆ

åœ¨é…ç½®æ–‡ä»¶ä¸­ä¸ºâ€œç”Ÿæˆå™¨â€å’Œâ€œç²¾ç‚¼å™¨â€ç»‘å®šå¯ç‹¬ç«‹é€‰æ‹©çš„ providerï¼Œç”¨æˆ·å¯æ ¹æ®éœ€æ±‚åˆ†åˆ«æŒ‡å‘ä¾¿å®œæˆ–é«˜è´¨é‡çš„æ¨¡å‹ã€‚é¡¹ç›®æœ¬èº«ä¸åšè‡ªåŠ¨æˆæœ¬è°ƒåº¦æˆ–åˆ†é˜¶æ®µç®¡çº¿ï¼Œåªæä¾›å¯é…ç½®çš„å¤šæ¨¡å‹èƒ½åŠ›ã€‚

### 2.3 å®ç°è¯æ®ï¼ˆå¯é…ç½®èƒ½åŠ›ï¼‰

#### é…ç½®ä½ç½®: `configs/binpacking.yaml`

```yaml
# é…ç½®ç¤ºä¾‹ï¼ˆå¯æ ¹æ®é¢„ç®—æ›¿æ¢ä¸ºä¸åŒæ¨¡å‹/ä¾›åº”å•†ï¼‰
llm_providers:
    - provider_id: main_provider
        provider_type: deepseek
        model_name: deepseek-chat
        base_url: https://api.deepseek.com
        temperature: 1.0

# ç”Ÿæˆ/ç²¾ç‚¼å¯æŒ‡å‘ä¸åŒ provider_idï¼ˆå½“å‰ç¤ºä¾‹æŒ‡å‘åŒä¸€ä¸ªï¼Œå¯æŒ‰éœ€æ‹†åˆ†ï¼‰
generator_provider_id: main_provider
refiner_provider_id: main_provider
```

#### å®ç°ä½ç½®: `experiments/runner.py`

```python
def _setup_providers(self, config: RunConfig) -> tuple[LLMProvider, LLMProvider]:
    generator = self._create_provider(config.generator_provider_id)
    refiner = self._create_provider(config.refiner_provider_id)
    return generator, refiner
```

### 2.4 ä½¿ç”¨å»ºè®®

- è‹¥éœ€è¦èŠ‚çœæˆæœ¬ï¼Œå¯å°† generator æŒ‡å‘ä¾¿å®œæ¨¡å‹ï¼Œå°† refiner æŒ‡å‘é«˜è´¨é‡æ¨¡å‹ã€‚
- è‹¥åªéœ€å¿«é€ŸéªŒè¯ï¼Œå¯å°†ä¸¤è€…æŒ‡å‘åŒä¸€ä¾¿å®œæ¨¡å‹ï¼ˆå¦‚å½“å‰ç¤ºä¾‹ï¼‰ã€‚
- æˆæœ¬ä¸è´¨é‡å–å†³äºç”¨æˆ·é€‰æ‹©çš„å…·ä½“æ¨¡å‹ä¸è°ƒç”¨æ¬¡æ•°ï¼Œé¡¹ç›®æœ¬èº«ä¸åšè‡ªåŠ¨æˆæœ¬ä¼°ç®—ã€‚

### 2.5 éªŒè¯æ–¹æ³•

è¿è¡Œå®éªŒåæ£€æŸ¥å€™é€‰çš„ provider_id åˆ†å¸ƒï¼ˆå¦‚é…ç½®äº†ä¸åŒ provider_idï¼Œå¯çœ‹åˆ°ä¸åŒåˆ†å¸ƒï¼›å•ä¸€ provider æ—¶åˆ†å¸ƒä¸€è‡´ï¼‰ï¼š

```bash
python -m experiments.cli run configs/binpacking.yaml
sqlite3 artifacts/binpacking_demo_001/candidates.db \
    "SELECT metadata->>'provider_id' as provider, COUNT(*) FROM candidates GROUP BY provider;"
```

---

## åˆ›æ–°ç‚¹ 3: å¤šæ ·æ€§é©±åŠ¨æœç´¢ (Novelty-Driven Search)

> **è¯¾ç¨‹å¯¹åº”**: "Novelty-driven FunSearch" - æ¢ç´¢å¤šæ ·åŒ–çš„è§£å†³æ–¹æ¡ˆï¼Œé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜

### 3.1 é—®é¢˜èƒŒæ™¯

ä¼ ç»Ÿè¿›åŒ–æœç´¢å®¹æ˜“é™·å…¥ **å±€éƒ¨æœ€ä¼˜**:

- æ‰€æœ‰å€™é€‰é€æ¸è¶‹åŒäºç›¸ä¼¼çš„ç­–ç•¥
- æœç´¢ç©ºé—´æ¢ç´¢ä¸å……åˆ†
- é”™è¿‡å¯èƒ½æ›´ä¼˜çš„"éç›´è§‰"è§£

**è¯¾ç¨‹åŸæ–‡**:
> *"Instead of always finding the best (in terms of some performance metric) solutions, we often would like to explore different ways to solve the same problem... we would like to find programs/codes with diversely different behaviors."*

### 3.2 è§£å†³æ–¹æ¡ˆ

å®æ–½ **å¤šæ ·æ€§é©±åŠ¨æœç´¢**ï¼ŒåŒ…å«ä¸¤ä¸ªæœºåˆ¶:

```
æœºåˆ¶ 1: å¤šå²›æ¨¡å‹ (Island Model)
  â”œâ”€ å¤šä¸ªç‹¬ç«‹å­ç§ç¾¤å¹¶è¡Œè¿›åŒ–
  â”œâ”€ æ¯ä¸ªå²›ä½¿ç”¨ä¸åŒå‚æ•° (temperature, é€‰æ‹©å‹åŠ›)
  â”œâ”€ å®šæœŸè¿ç§»: å²›é—´äº¤æ¢ä¼˜è´¨ä¸ªä½“
  â””â”€ æ•ˆæœ: å¹¶è¡Œæ¢ç´¢å¤šä¸ªæœç´¢æ–¹å‘

æœºåˆ¶ 2: è¡Œä¸ºç­¾åå¤šæ ·æ€§ (Behavior Signature Diversity)
  â”œâ”€ è®¡ç®—å€™é€‰åœ¨æ¢é’ˆå®ä¾‹ä¸Šçš„è¡Œä¸ºç­¾å
  â”œâ”€ ç­¾å = å€™é€‰åœ¨å›ºå®šæµ‹è¯•ä¸Šçš„å†³ç­–åºåˆ—
  â”œâ”€ ç›¸ä¼¼ç­¾å â†’ ç›¸ä¼¼è¡Œä¸º â†’ è£å‰ªé‡å¤
  â””â”€ æ•ˆæœ: ä¿ç•™è¡Œä¸ºå¤šæ ·çš„å€™é€‰
```

### 3.3 å®ç°è¯æ®

#### ä»£ç ä½ç½® 1: `funsearch_core/islands.py`

```python
@dataclass
class Island:
    population: Population
    parameters: dict[str, object]  # æ¯ä¸ªå²›çš„ç‹¬ç«‹å‚æ•°


class IslandManager:
    def __init__(
        self,
        num_islands: int,
        population_factory: Callable[[], Population],
        island_parameters: list[dict[str, object]] | None = None,
    ) -> None:
        # åˆ›å»ºå¤šä¸ªç‹¬ç«‹å²›
        self._islands: list[Island] = []
        for idx in range(num_islands):
            self._islands.append(Island(
                population_factory(), 
                dict(island_parameters[idx])
            ))

    def migrate(self, num_migrants: int = 1) -> int:
        """å²›é—´è¿ç§»: æ¯ä¸ªå²›å‘ä¸‹ä¸€ä¸ªå²›å‘é€æœ€ä¼˜ä¸ªä½“"""
        migrated = 0
        for idx, island in enumerate(self._islands):
            # è·å–æœ¬å²›æœ€ä¼˜å€™é€‰
            migrants = island.population.get_top_k(num_migrants)
            if not migrants:
                continue
            # å‘é€åˆ°ä¸‹ä¸€ä¸ªå²› (ç¯å½¢æ‹“æ‰‘)
            target = self._islands[(idx + 1) % len(self._islands)].population
            for candidate in migrants:
                cloned = candidate.model_copy(deep=True)
                if target.add_candidate(cloned):
                    migrated += 1
        return migrated
```

#### ä»£ç ä½ç½® 2: `funsearch_core/diversity.py`

```python
@dataclass(frozen=True)
class SignatureResult:
    signature: str       # è¡Œä¸ºç­¾åå“ˆå¸Œ
    vector: list[float]  # è¡Œä¸ºå‘é‡


class SignatureCalculator:
    def __init__(
        self,
        probe_runner: Callable[[str, int], object],  # åœ¨æ¢é’ˆå®ä¾‹ä¸Šè¿è¡Œä»£ç 
        probe_seeds: Sequence[int] | None = None,    # æ¢é’ˆç§å­
    ) -> None:
        self._probe_runner = probe_runner
        self._probe_seeds = list(probe_seeds) if probe_seeds else [0, 1, 2, 3, 4]

    def calculate(self, candidate_or_code: Candidate | str) -> SignatureResult:
        """è®¡ç®—å€™é€‰çš„è¡Œä¸ºç­¾å"""
        code = candidate_or_code.code if isinstance(candidate_or_code, Candidate) else candidate_or_code
        vector: list[float] = []
        # åœ¨å¤šä¸ªæ¢é’ˆå®ä¾‹ä¸Šè¿è¡Œï¼Œè®°å½•è¡Œä¸º
        for seed in self._probe_seeds:
            value = self._probe_runner(code, seed)
            vector.append(float(value))
        # å“ˆå¸Œç”Ÿæˆç­¾å
        signature = self._hash_vector(vector)
        return SignatureResult(signature=signature, vector=vector)


class DiversityMaintainer:
    def __init__(
        self,
        min_distance: float = 0.1,  # æœ€å°è¡Œä¸ºè·ç¦»
        metric: str = "cosine",     # è·ç¦»åº¦é‡
    ) -> None:
        self.min_distance = min_distance
        self.metric = metric

    def is_diverse(self, candidate: Candidate, existing: Iterable[Candidate]) -> bool:
        """åˆ¤æ–­å€™é€‰æ˜¯å¦ä¸ç°æœ‰ç§ç¾¤è¶³å¤Ÿä¸åŒ"""
        for other in existing:
            # ç­¾åç›¸åŒ = è¡Œä¸ºç­‰ä»·
            if candidate.signature == other.signature:
                return False
            # è¡Œä¸ºå‘é‡è·ç¦»è¿‡è¿‘
            distance = self._distance(candidate.vector, other.vector)
            if distance < self.min_distance:
                return False
        return True

    def _distance(self, vector_a, vector_b) -> float:
        """è®¡ç®—ä½™å¼¦è·ç¦»æˆ–æ±‰æ˜è·ç¦»"""
        if self.metric == "hamming":
            return _hamming_distance(vector_a, vector_b)
        return _cosine_distance(vector_a, vector_b)
```

#### è°ƒç”¨ä½ç½®: `funsearch_core/loop.py`

```python
class FunSearchLoop:
    def __init__(
        self,
        # ...
        diversity_maintainer: DiversityMaintainer | None = None,
        island_manager: IslandManager | None = None,
        migration_interval: int = 0,  # æ¯Nä»£è¿ç§»ä¸€æ¬¡
        migration_size: int = 1,      # æ¯æ¬¡è¿ç§»çš„ä¸ªä½“æ•°
    ) -> None:
        self.diversity_maintainer = diversity_maintainer
        self.islands = island_manager or self._create_default_islands()
        self.migration_interval = migration_interval
        self.migration_size = migration_size

    def run_generation(self) -> dict[str, object]:
        # å¯¹æ¯ä¸ªå²›ç‹¬ç«‹è¿è¡Œ
        for island_index, island in enumerate(self.islands.islands):
            new_candidates = self._generate_candidates_for_island(island_index)
            
            # å¤šæ ·æ€§è¿‡æ»¤
            if self.diversity_maintainer:
                new_candidates = [
                    c for c in new_candidates
                    if self.diversity_maintainer.is_diverse(c, island.population)
                ]
            
            self._evaluate_candidates(new_candidates)
            island.population.update(new_candidates)
        
        # å®šæœŸæ‰§è¡Œå²›é—´è¿ç§»
        if self.generation % self.migration_interval == 0:
            self.islands.migrate(self.migration_size)
```

#### é…ç½®ä½ç½®: `configs/binpacking.yaml`

```yaml
num_islands: 3              # 3ä¸ªç‹¬ç«‹å²›
migration_interval: 5       # æ¯5ä»£è¿ç§»ä¸€æ¬¡
migration_size: 1           # æ¯æ¬¡è¿ç§»1ä¸ªå€™é€‰

# æ¯ä¸ªå²›çš„ç‹¬ç«‹å‚æ•° (å¯é€‰)
island_parameters:
  - temperature: 0.6        # å²›1: ä½æ¸©åº¦ï¼Œæ›´ä¿å®ˆ
  - temperature: 0.8        # å²›2: ä¸­ç­‰æ¸©åº¦
  - temperature: 1.0        # å²›3: é«˜æ¸©åº¦ï¼Œæ›´æ¿€è¿›
```

### 3.4 æ•ˆæœåˆ†æ

**ä¼ ç»Ÿå•ç§ç¾¤æœç´¢**:
- æ‰€æœ‰å€™é€‰ç«äº‰åŒä¸€ä¸ªç§ç¾¤
- ç›¸ä¼¼ç­–ç•¥é€æ¸å æ®ä¸»å¯¼
- å®¹æ˜“æ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜

**å¤šæ ·æ€§é©±åŠ¨æœç´¢**:
- å¤šå²›å¹¶è¡Œæ¢ç´¢ä¸åŒæ–¹å‘
- è¡Œä¸ºç­¾åè¿‡æ»¤ç›¸ä¼¼å€™é€‰
- ä¿æŒç§ç¾¤å¤šæ ·æ€§

**é¢„æœŸæ”¶ç›Š**:
- âœ… æ¢ç´¢æ›´å¹¿çš„æœç´¢ç©ºé—´
- âœ… å‘ç°å¤šç§ä¸åŒç­–ç•¥
- âœ… é¿å…è¿‡æ—©æ”¶æ•›
- âœ… æœ€ç»ˆè§£è´¨é‡æ›´é«˜

### 3.5 éªŒè¯æ–¹æ³•

```bash
# è¿è¡Œå®éªŒ
python -m experiments.cli run configs/binpacking.yaml

# æ£€æŸ¥å²›é—´å¤šæ ·æ€§
sqlite3 artifacts/binpacking_demo_001/candidates.db \
  "SELECT json_extract(metadata, '$.island_id') as island, 
          COUNT(DISTINCT signature) as unique_behaviors
   FROM candidates 
   GROUP BY island;"

# é¢„æœŸ: ä¸åŒå²›æœ‰ä¸åŒæ•°é‡çš„ç‹¬ç‰¹è¡Œä¸ºç­¾å

# æ£€æŸ¥è¿ç§»è®°å½•
grep "migrate" artifacts/binpacking_demo_001/metrics.jsonl
```

é¢„æœŸè¾“å‡º:
```
island | unique_behaviors
0      | 15
1      | 18
2      | 12
```

### 3.6 ä¸è¯¾ç¨‹ Novelty Search çš„è”ç³»

è¯¾ç¨‹æ¨èå‚è€ƒ Ken Stanley çš„ "Novelty Search" æ€æƒ³:
> *"Why greatness can not be planned"* - æœ‰æ—¶å€™è¿½æ±‚å¤šæ ·æ€§æ¯”è¿½æ±‚æœ€ä¼˜æ›´æœ‰æ•ˆ

æœ¬å®ç°çš„å¯¹åº”:
- **å¤šå²›æ¨¡å‹** â†’ å¹¶è¡Œæ¢ç´¢å¤šä¸ª"æ–¹å‘"
- **è¡Œä¸ºç­¾å** â†’ åº¦é‡å€™é€‰ä¹‹é—´çš„"æ–°é¢–æ€§"
- **å¤šæ ·æ€§è¿‡æ»¤** â†’ ä¿ç•™"æ–°é¢–"çš„å€™é€‰

---

## å·¥ç¨‹ç‰¹æ€§: æœç´¢è½¨è¿¹å¯è§‚æµ‹æ€§

> **æ³¨æ„**: å¯è§‚æµ‹æ€§æ˜¯å·¥ç¨‹ç‰¹æ€§ï¼Œä¸æ˜¯ç®—æ³•åˆ›æ–°ç‚¹ï¼Œä½†å¯¹è¯¾ç¨‹æŠ¥å‘Šéå¸¸æœ‰ç”¨ã€‚

ç³»ç»Ÿæä¾›å…¨æ–¹ä½å¯è§‚æµ‹æ€§:
- **å®æ—¶è¿›åº¦æ¡**: tqdm æ˜¾ç¤ºå€™é€‰ç”Ÿæˆè¿›åº¦ã€é¢„è®¡æ€»æ—¶é—´ (`funsearch_core/loop.py`)
- **å®æ—¶æŒ‡æ ‡**: æ¯ä»£è®°å½•æœ€ä½³/å¹³å‡åˆ†æ•°ã€å¤±è´¥ç»Ÿè®¡ (`experiments/metrics.py`)
- **å¯è§†åŒ–**: è¿›åŒ–æ›²çº¿ã€å¤±è´¥åˆ†å¸ƒé¥¼å›¾ (`experiments/plotting.py`)
- **å·¥ä»¶ç®¡ç†**: é…ç½®å¿«ç…§ã€å€™é€‰æ•°æ®åº“ã€æœ€ä½³å€™é€‰å¯¼å‡º

**è¿›åº¦æ¡ç¤ºä¾‹**:
```
==================================================
  FunSearch Evolution Started
==================================================

ğŸ§¬ Evolution:  10%|â–ˆâ–ˆâ–ˆâ–ˆ                          | 5/50 [00:32<04:52]
  ğŸ”¥ NEW BEST! Score: 45.2000
   ğŸ’¾ Checkpoint saved at generation 10

==================================================
  Completed 50 generations
  Best Score: 45.2000
==================================================
```

è¯¦è§ `artifacts/` ç›®å½•ä¸‹çš„è¾“å‡ºæ–‡ä»¶ã€‚

---

## å·¥ç¨‹ç‰¹æ€§: æ ‡å‡†åŸºå‡†æ•°æ®é›†

ç³»ç»Ÿå†…ç½® OR-Library è£…ç®±é—®é¢˜æ ‡å‡†æµ‹è¯•é›†:
- **æ•°æ®é›†åŠ è½½**: `evaluator/datasets.py`
- **160 ä¸ªæ ‡å‡†å®ä¾‹**: binpack1-8.txt
- **ä¸¤ç±»åˆ†å¸ƒ**: Uniform (u*) å’Œ Triplet (t*)
- **åŸºå‡†å¯¹æ¯”**: `BenchmarkEvaluator` æ”¯æŒä¸ best_known å¯¹æ¯”

```python
from evaluator.datasets import load_orlib_small, load_orlib_large

# åŠ è½½å°å‹å®ä¾‹ (80ä¸ªï¼Œç”¨äºå¿«é€Ÿæµ‹è¯•)
small = load_orlib_small()

# åŠ è½½å¤§å‹å®ä¾‹ (80ä¸ªï¼Œç”¨äºå®Œæ•´è¯„ä¼°)
large = load_orlib_large()
```

---

## æ€»ç»“å¯¹æ¯”

| ä¼ ç»Ÿå®ç° | FunSearch-Lite (æœ¬é¡¹ç›®) | è¯¾ç¨‹å¯¹åº” | æ”¹è¿› |
|---------|------------------------|---------|------|
| è¯­æ³•çº§ä»£ç å»é‡ | **åŠŸèƒ½çº§å»é‡** (è¡Œä¸ºç­¾å) | Sample-efficient | LLM è°ƒç”¨â†“30-50% |
| å•ä¸€æ¨¡å‹ç”Ÿæˆ | å¯é…ç½®å¤šæ¨¡å‹ (ç”Ÿæˆå™¨ + ç²¾ç‚¼å™¨) | æˆæœ¬/è´¨é‡å¯è°ƒ | ç”±ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹å†³å®šæˆæœ¬ä¸ç²¾åº¦ |
| å•ä¸€ç§ç¾¤æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ | å¤šå²›æ¨¡å‹ + è¡Œä¸ºç­¾åå¤šæ ·æ€§ | Novelty-driven | æ¢ç´¢æ›´å¤šæœç´¢ç©ºé—´ |

## å®éªŒéªŒè¯æ¸…å•

è¦éªŒè¯è¿™ä¸‰ä¸ªåˆ›æ–°ç‚¹ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤:

```bash
# æ–¹å¼ä¸€: ä½¿ç”¨å¯åŠ¨è„šæœ¬ (æ¨è)
# 1. åˆ›å»º .env æ–‡ä»¶ä¿å­˜ API Key (åªéœ€ä¸€æ¬¡)
echo "DEEPSEEK_API_KEY=sk-xxx" > .env

# 2. è¿è¡Œå®éªŒ
python run.py                        # é»˜è®¤é…ç½® (éšæœº/å°)
python run.py -d orlib -s large      # OR-Library å¤§å‹æ•°æ®é›†
python run.py -g 3 -p 3 -y           # å¿«é€Ÿæµ‹è¯• (~5åˆ†é’Ÿ)

# æ–¹å¼äºŒ: ä½¿ç”¨ CLI
python -m experiments.cli run configs/binpacking_deepseek.yaml

# 2. éªŒè¯åŠŸèƒ½çº§å»é‡ (åˆ›æ–°ç‚¹1)
python -m pytest tests/test_deduplication.py -v
# é¢„æœŸ: test_different_code_same_behavior_is_duplicate é€šè¿‡
# è¿™éªŒè¯äº†æ ¸å¿ƒèƒ½åŠ›: ä¸åŒä»£ç ä½†ç›¸åŒè¡Œä¸ºè¢«æ£€æµ‹ä¸ºé‡å¤

# æ£€æŸ¥å»é‡ç»Ÿè®¡
sqlite3 artifacts/binpacking_deepseek_002/candidates.db \
  "SELECT COUNT(*) as total_generated,
          SUM(CASE WHEN json_extract(metadata, '$.skipped_duplicate') = 1 THEN 1 ELSE 0 END) as skipped_duplicates
   FROM candidates;"
# é¢„æœŸ: skipped_duplicates / total_generated â‰ˆ 20-40%

# 3. éªŒè¯å¯é…ç½®å¤šæ¨¡å‹ (åˆ›æ–°ç‚¹2)
sqlite3 artifacts/binpacking_deepseek_002/candidates.db \
  "SELECT json_extract(metadata, '$.provider_id') as provider, COUNT(*) 
   FROM candidates 
   GROUP BY provider;"
# é¢„æœŸ: æ˜¾ç¤º provider_id åˆ†å¸ƒ

# 4. éªŒè¯å¤šæ ·æ€§é©±åŠ¨ (åˆ›æ–°ç‚¹3)
sqlite3 artifacts/binpacking_deepseek_002/candidates.db \
  "SELECT json_extract(metadata, '$.island_id') as island, 
          COUNT(DISTINCT signature) as unique_behaviors
   FROM candidates 
   GROUP BY island;"
# é¢„æœŸ: ä¸åŒå²›æœ‰ä¸åŒçš„ç‹¬ç‰¹è¡Œä¸ºç­¾å
```

## è¯¾ç¨‹æŠ¥å‘Šå»ºè®®

åœ¨è¯¾ç¨‹æŠ¥å‘Šä¸­ï¼Œå¯ä»¥è¿™æ ·ç»„ç»‡å†…å®¹:

1. **ç« èŠ‚ 3.1 - åŠŸèƒ½çº§å»é‡ (Sample-efficient)**
   - è´´ä¸Š `funsearch_core/deduplication.py` å…³é”®ä»£ç ç‰‡æ®µ
   - å¼ºè°ƒæ ¸å¿ƒæ´è§: "ä¸åŒä»£ç  + ç›¸åŒè¡Œä¸º = åŠŸèƒ½ç­‰ä»· = è·³è¿‡è¯„ä¼°"
   - å±•ç¤ºå»é‡èŠ‚çœçš„ LLM è°ƒç”¨æ¬¡æ•°ç»Ÿè®¡
   - å¼•ç”¨æµ‹è¯• `test_different_code_same_behavior_is_duplicate` è¯æ˜åŠŸèƒ½æ­£ç¡®

2. **ç« èŠ‚ 3.2 - å¯é…ç½®å¤šæ¨¡å‹ (Configurable)**
    - è´´ä¸Š `experiments/runner.py` å’Œ `configs/binpacking.yaml` é…ç½®
    - è¯´æ˜å¯ç‹¬ç«‹é€‰æ‹©ç”Ÿæˆå™¨/ç²¾ç‚¼å™¨çš„ providerï¼Œçªå‡ºçµæ´»æ€§
    - å±•ç¤ºå€™é€‰çš„ provider_id åˆ†å¸ƒç»Ÿè®¡ï¼ˆè‹¥é…ç½®äº†ä¸åŒ providerï¼‰

3. **ç« èŠ‚ 3.3 - å¤šæ ·æ€§é©±åŠ¨æœç´¢ (Novelty-driven)**
   - è´´ä¸Š `funsearch_core/islands.py` å’Œ `diversity.py` å…³é”®ä»£ç 
   - å±•ç¤ºä¸åŒå²›çš„è¡Œä¸ºå¤šæ ·æ€§ç»Ÿè®¡
   - å¯¹æ¯”å•ç§ç¾¤ vs å¤šå²›æ¨¡å‹çš„æ”¶æ•›æ›²çº¿

4. **ç« èŠ‚ 4 - å®éªŒç»“æœ**
   - å±•ç¤ºæœ€ç»ˆæ‰¾åˆ°çš„æœ€ä½³ `score_bin` å‡½æ•°
   - å¯¹æ¯” First-Fit åŸºçº¿å’Œ FunSearch ç»“æœ
   - è®¨è®ºæ”¶æ•›é€Ÿåº¦å’Œè´¨é‡
   - å±•ç¤ºè¿›åŒ–æ›²çº¿å’Œå¤±è´¥åˆ†å¸ƒå›¾ (å¯è§‚æµ‹æ€§è¾“å‡º)

## ç›¸å…³æµ‹è¯•ç”¨ä¾‹

æ‰€æœ‰ä¸‰ä¸ªåˆ›æ–°ç‚¹éƒ½æœ‰å¯¹åº”çš„æµ‹è¯•è¦†ç›–:

```
tests/test_deduplication.py      # æµ‹è¯•åŠŸèƒ½çº§å»é‡
tests/test_experiments.py        # æµ‹è¯•å¤šæ¨¡å‹é…ç½®
tests/test_funsearch_core.py     # æµ‹è¯•å¤šå²›æ¨¡å‹å’Œå¤šæ ·æ€§ç»´æŠ¤
```

è¿è¡Œæµ‹è¯•:
```bash
python -m pytest tests/ -v
```

é¢„æœŸ: æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œç¡®è®¤ä¸‰ä¸ªåˆ›æ–°ç‚¹çš„å®ç°æ­£ç¡®æ€§ã€‚
