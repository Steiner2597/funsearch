# Usage Guide (ä½¿ç”¨æŒ‡å—)

æœ¬æ–‡æ¡£æä¾› FunSearch-Lite çš„è¯¦ç»†ä½¿ç”¨è¯´æ˜ï¼ŒåŒ…æ‹¬å®‰è£…ã€é…ç½®ã€è¿è¡Œå®éªŒå’Œç»“æœåˆ†æã€‚

## ç›®å½•

1. [å®‰è£…](#1-å®‰è£…)
2. [å¿«é€Ÿå¼€å§‹](#2-å¿«é€Ÿå¼€å§‹)
3. [é…ç½®è¯¦è§£](#3-é…ç½®è¯¦è§£)
4. [è¿è¡Œå®éªŒ](#4-è¿è¡Œå®éªŒ)
5. [ç»“æœåˆ†æ](#5-ç»“æœåˆ†æ)
6. [æ ‡å‡†æ•°æ®é›†](#6-æ ‡å‡†æ•°æ®é›†)
7. [é«˜çº§ç”¨æ³•](#7-é«˜çº§ç”¨æ³•)
8. [æ•…éšœæ’é™¤](#8-æ•…éšœæ’é™¤)

---

## 1. å®‰è£…

### 1.1 ç³»ç»Ÿè¦æ±‚

- **Python**: 3.10 æˆ–æ›´é«˜
- **æ“ä½œç³»ç»Ÿ**: Linux, macOS, Windows
- **å†…å­˜**: è‡³å°‘ 2GB RAM
- **ç£ç›˜**: è‡³å°‘ 500MB å¯ç”¨ç©ºé—´

### 1.2 å…‹éš†é¡¹ç›®

```bash
# å‡è®¾é¡¹ç›®å·²åœ¨å½“å‰ç›®å½•
cd /path/to/funsearch
```

### 1.3 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (æ¨è)

```bash
# ä½¿ç”¨ venv
python -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate   # Windows

# æˆ–ä½¿ç”¨ conda
conda create -n funsearch python=3.10
conda activate funsearch
```

### 1.4 å®‰è£…ä¾èµ–

```bash
# æ–¹å¼ 1: ä½¿ç”¨ pip (å¯ç¼–è¾‘æ¨¡å¼)
pip install -e .

# æ–¹å¼ 2: æ‰‹åŠ¨å®‰è£…ä¾èµ–
pip install pydantic pyyaml typer matplotlib openai tqdm
```

### 1.5 éªŒè¯å®‰è£…

```bash
# è¿è¡Œæµ‹è¯•å¥—ä»¶
python -m pytest tests/ -v

# æ£€æŸ¥ CLI
python -m experiments.cli --help
```

é¢„æœŸè¾“å‡º:
```
48 passed, 1 skipped  # openai åŒ…æœªå®‰è£…æ—¶è·³è¿‡ 1 ä¸ªæµ‹è¯•
```

---

## 2. å¿«é€Ÿå¼€å§‹

### 2.1 è¿è¡Œæ¼”ç¤ºå®éªŒ (FakeProvider)

æ— éœ€ API keyï¼Œä½¿ç”¨å†…ç½®çš„ FakeProvider:

```bash
python -m experiments.cli run configs/binpacking.yaml
```

é¢„æœŸè¾“å‡º:
```
ğŸš€ Starting experiment: binpacking_demo_001
   Max generations: 20
   Population size: 50
   Islands: 3
   Task: bin_packing

==================================================
  FunSearch Evolution Started
==================================================

ğŸ§¬ Evolution:  10%|â–ˆâ–ˆâ–ˆâ–ˆ                          | 5/50 [00:32<04:52]
  ğŸ”¥ NEW BEST! Score: 42.5000

==================================================
  Completed 50 generations
  Best Score: 42.5000
==================================================
```

### 2.2 ä½¿ç”¨ DeepSeek API (æ¨è)

DeepSeek æä¾›æ€§ä»·æ¯”å¾ˆé«˜çš„ API æœåŠ¡:

**æ–¹å¼ä¸€ï¼šä½¿ç”¨å¯åŠ¨è„šæœ¬ (æ¨è)**

```bash
# åˆ›å»º .env æ–‡ä»¶ (åªéœ€ä¸€æ¬¡ï¼ŒAPI Key ä¼šè‡ªåŠ¨åŠ è½½)
echo "DEEPSEEK_API_KEY=sk-xxx" > .env

# å¯åŠ¨å®éªŒ
python run.py                        # é»˜è®¤é…ç½®
python run.py -d orlib -s large      # OR-Library å¤§å‹æ•°æ®é›†
python run.py -g 3 -p 3 -y           # å¿«é€Ÿæµ‹è¯• (~5åˆ†é’Ÿ)
python run.py --help                 # æŸ¥çœ‹æ‰€æœ‰é€‰é¡¹
```

**æ–¹å¼äºŒï¼šæ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡**

```bash
# Linux/macOS:
export DEEPSEEK_API_KEY="sk-..."

# Windows PowerShell:
$env:DEEPSEEK_API_KEY = "sk-..."

# è¿è¡Œå®éªŒ
python -m experiments.cli run configs/binpacking_deepseek.yaml
```

### 2.3 ä½¿ç”¨ OpenAI API

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY="sk-..."

# ä¿®æ”¹é…ç½®æ–‡ä»¶ä½¿ç”¨ OpenAI
cp configs/binpacking.yaml configs/my_experiment.yaml
# ç¼–è¾‘ my_experiment.yaml, å°† provider_type æ”¹ä¸º "openai"

# è¿è¡Œå®éªŒ
python -m experiments.cli run configs/my_experiment.yaml
```

### 2.4 æŸ¥çœ‹ç»“æœ

```bash
# åˆ—å‡ºæ‰€æœ‰å®éªŒ
python -m experiments.cli list-runs

# å¯¼å‡ºæœ€ä½³å€™é€‰
python -m experiments.cli export-best binpacking_deepseek_002

# æŸ¥çœ‹å¯¼å‡ºçš„ä»£ç 
cat artifacts/binpacking_deepseek_002/best_candidate.py

# æŸ¥çœ‹å¯è§†åŒ–
ls artifacts/binpacking_deepseek_002/plots/
```

---

## 3. é…ç½®è¯¦è§£

### 3.1 é…ç½®æ–‡ä»¶ç»“æ„

é…ç½®æ–‡ä»¶ä½¿ç”¨ YAML æ ¼å¼ï¼Œä½äº `configs/` ç›®å½•ã€‚

**DeepSeek é…ç½®ç¤ºä¾‹** (`configs/binpacking_deepseek.yaml`):

```yaml
# ============== å®éªŒæ ‡è¯† ==============
run_id: "binpacking_deepseek_002"
seed: 42

# ============== æœç´¢å‚æ•° ==============
max_generations: 50
population_size: 15
num_islands: 3
top_k_for_full_eval: 5

# ============== é—®é¢˜å®šä¹‰ ==============
task_name: "bin_packing"

evaluator:
  # æ•°æ®é›†ç±»å‹: "random" (éšæœºç”Ÿæˆ) æˆ– "orlib" (OR-Library)
  type: "random"
  # å®ä¾‹å¤§å°: "small" æˆ– "large"
  size: "small"
  capacity: 100
  seed: 42

# ============== LLM æä¾›è€… ==============
llm_providers:
  - provider_id: "deepseek_generator"
    provider_type: "deepseek"
    model_name: "deepseek-chat"
    base_url: "https://api.deepseek.com"
    max_retries: 3
    timeout_seconds: 60
    temperature: 1.0
    max_tokens: 2000

generator_provider_id: "deepseek_generator"
refiner_provider_id: "deepseek_generator"

# ============== è¾“å‡ºé…ç½® ==============
artifact_dir: "artifacts"
save_interval: 5
```

### 3.2 æ•°æ®é›†é€‰é¡¹

| é…ç½® | å‘½ä»¤è¡Œ | è¯´æ˜ |
|------|--------|------|
| `type: "random"` + `size: "small"` | `python run.py` | 5-10ä¸ªç‰©å“ï¼Œå¿«é€Ÿæµ‹è¯• |
| `type: "random"` + `size: "large"` | `python run.py -s large` | 50-100ä¸ªç‰©å“ï¼Œæ›´çœŸå® |
| `type: "orlib"` + `size: "small"` | `python run.py -d orlib` | OR-Library binpack1-4 (80å®ä¾‹) |
| `type: "orlib"` + `size: "large"` | `python run.py -d orlib -s large` | OR-Library binpack5-8 (80å®ä¾‹) |

### 3.3 å…³é”®å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `run_id` | string | (å¿…éœ€) | å®éªŒå”¯ä¸€æ ‡è¯†ï¼Œç”¨ä½œå·¥ä»¶ç›®å½•å |
| `seed` | int | (æ¨è) | éšæœºç§å­ï¼Œç¡®ä¿å¯é‡ç°æ€§ |
| `max_generations` | int | 20 | è¿è¡Œçš„ä»£æ•° |
| `population_size` | int | 50 | æ¯ä»£ç”Ÿæˆçš„å€™é€‰æ•°é‡ |
| `num_islands` | int | 3 | å¤šå²›æ¨¡å‹çš„å²›å±¿æ•° (1 = å•å²›) |
| `top_k_for_full_eval` | int | 10 | ä»…å¯¹æœ€ä¼˜ K ä¸ªå€™é€‰æ‰§è¡Œå®Œæ•´è¯„ä¼° |
| `task_name` | string | "bin_packing" | ä»»åŠ¡åç§° (å¿…é¡»åŒ¹é…è¯„ä¼°å™¨) |
| `evaluator.type` | string | "random" | æ•°æ®é›†ç±»å‹: "random" æˆ– "orlib" |
| `evaluator.size` | string | "small" | å®ä¾‹å¤§å°: "small" æˆ– "large" |
| `generator_provider_id` | string | (å¿…éœ€) | ç”Ÿæˆå™¨ LLM ID |
| `refiner_provider_id` | string | (å¯é€‰) | ç²¾ç‚¼å™¨ LLM ID (å¯ä¸ç”Ÿæˆå™¨ç›¸åŒ) |

### 3.4 é…ç½®å¤šä¸ª LLM æä¾›è€… (å¤šæ¨¡å‹åä½œ)

```yaml
llm_providers:
  # å»‰ä»·ç”Ÿæˆå™¨ (ç”¨äºæ‰¹é‡ç”Ÿæˆ)
  - provider_id: "cheap_gen"
    provider_type: "openai"
    model_name: "gpt-3.5-turbo"
    temperature: 0.8
    max_retries: 3
  
  # å¼ºå¤§ç²¾ç‚¼å™¨ (ç”¨äºä¼˜åŒ– Top-K)
  - provider_id: "strong_refine"
    provider_type: "openai"
    model_name: "gpt-4"
    temperature: 0.3
    max_retries: 5

# åˆ†é…ä¸åŒæ¨¡å‹ç»™ä¸åŒé˜¶æ®µ
generator_provider_id: "cheap_gen"
refiner_provider_id: "strong_refine"
```

### 3.4 è°ƒæ•´æœç´¢å¼ºåº¦

**å¿«é€Ÿæµ‹è¯• (5åˆ†é’Ÿ)**:
```yaml
max_generations: 10
population_size: 20
top_k_for_full_eval: 5
```

**æ ‡å‡†æœç´¢ (30åˆ†é’Ÿ)**:
```yaml
max_generations: 50
population_size: 50
top_k_for_full_eval: 10
```

**æ·±åº¦æœç´¢ (2å°æ—¶)**:
```yaml
max_generations: 200
population_size: 100
top_k_for_full_eval: 20
```

---

## 4. è¿è¡Œå®éªŒ

### 4.1 å‘½ä»¤è¡Œç•Œé¢

FunSearch-Lite æä¾› 4 ä¸ªä¸»è¦å‘½ä»¤:

```bash
python3 -m experiments.cli [COMMAND] [OPTIONS]
```

#### å‘½ä»¤ 1: `run` - è¿è¡Œå®éªŒ

```bash
python3 -m experiments.cli run <config_file>
```

**ç¤ºä¾‹**:
```bash
python3 -m experiments.cli run configs/binpacking.yaml
```

**é€‰é¡¹**:
- æš‚æ— é¢å¤–é€‰é¡¹ (æ‰€æœ‰é…ç½®é€šè¿‡ YAML æ–‡ä»¶æŒ‡å®š)

#### å‘½ä»¤ 2: `list-runs` - åˆ—å‡ºæ‰€æœ‰å®éªŒ

```bash
python3 -m experiments.cli list-runs
```

**è¾“å‡ºç¤ºä¾‹**:
```
Run ID                   | Status    | Generations | Best Score
-------------------------|-----------|-------------|------------
binpacking_demo_001      | completed | 20          | -10.5
my_experiment_002        | completed | 50          | -9.2
test_run_003             | incomplete| 15          | -12.1
```

#### å‘½ä»¤ 3: `export-best` - å¯¼å‡ºæœ€ä½³å€™é€‰

```bash
python3 -m experiments.cli export-best <run_id>
```

**ç¤ºä¾‹**:
```bash
python3 -m experiments.cli export-best binpacking_demo_001
```

**è¾“å‡º**:
```
Best candidate exported to: artifacts/binpacking_demo_001/best_candidate.py
Score: -10.5
```

**å¯¼å‡ºæ–‡ä»¶å†…å®¹** (`best_candidate.py`):
```python
"""
Best candidate from run: binpacking_demo_001
Score: -10.5
Generated at: 2024-01-15 10:45:00
"""

def score_bin(item_size: int, remaining_capacity: int, bin_index: int, step: int) -> float:
    """LLM ç”Ÿæˆçš„å¯å‘å¼å‡½æ•°"""
    # ... è‡ªåŠ¨ç”Ÿæˆçš„ä»£ç  ...
    return score
```

#### å‘½ä»¤ 4: `resume` - æ¢å¤ä¸­æ–­çš„å®éªŒ

```bash
python3 -m experiments.cli resume <run_id>
```

**ç”¨é€”**: ä»æœ€åä¿å­˜çš„æ£€æŸ¥ç‚¹æ¢å¤å®éªŒ (éœ€è¦åœ¨é…ç½®ä¸­è®¾ç½® `save_interval`)

### 4.2 å·¥ä»¶ç›®å½•ç»“æ„

æ¯æ¬¡è¿è¡Œä¼šåœ¨ `artifacts/<run_id>/` åˆ›å»ºä»¥ä¸‹æ–‡ä»¶:

```
artifacts/binpacking_demo_001/
â”œâ”€â”€ config.yaml              # é…ç½®å¿«ç…§ (å®éªŒçš„å®Œæ•´é…ç½®)
â”œâ”€â”€ candidates.db            # SQLite æ•°æ®åº“ (æ‰€æœ‰å€™é€‰)
â”œâ”€â”€ llm_cache.db             # LLM å“åº”ç¼“å­˜ (é™ä½é‡å¤æˆæœ¬)
â”œâ”€â”€ metrics.jsonl            # æ¯ä»£æŒ‡æ ‡ (JSONL æ ¼å¼, é€è¡Œè¿½åŠ )
â”œâ”€â”€ metrics.csv              # æŒ‡æ ‡ CSV ç‰ˆæœ¬ (ä¾¿äºåˆ†æ)
â”œâ”€â”€ best_candidate.py        # å¯¼å‡ºçš„æœ€ä½³å€™é€‰ä»£ç 
â””â”€â”€ plots/
    â”œâ”€â”€ evolution.png        # è¿›åŒ–æ›²çº¿å›¾
    â””â”€â”€ failures.png         # å¤±è´¥åˆ†å¸ƒé¥¼å›¾
```

### 4.3 å®æ—¶ç›‘æ§

å®éªŒè¿è¡Œæ—¶ï¼Œå¯ä»¥åœ¨å¦ä¸€ä¸ªç»ˆç«¯å®æ—¶ç›‘æ§:

```bash
# å®æ—¶æŸ¥çœ‹æŒ‡æ ‡
tail -f artifacts/binpacking_demo_001/metrics.jsonl

# æŸ¥è¯¢å½“å‰æœ€ä½³åˆ†æ•°
sqlite3 artifacts/binpacking_demo_001/candidates.db \
  "SELECT MAX(score) FROM candidates WHERE score IS NOT NULL;"

# ç»Ÿè®¡æœ‰æ•ˆå€™é€‰æ•°
sqlite3 artifacts/binpacking_demo_001/candidates.db \
  "SELECT COUNT(*) FROM candidates WHERE score IS NOT NULL;"
```

---

## 5. ç»“æœåˆ†æ

### 5.1 æŸ¥çœ‹æŒ‡æ ‡æ–‡ä»¶

**JSONL æ ¼å¼** (æ¯ä»£ä¸€è¡Œ):
```bash
cat artifacts/binpacking_demo_001/metrics.jsonl | jq .
```

**ç¤ºä¾‹è¾“å‡º**:
```json
{
  "generation": 0,
  "best_score": -15.2,
  "avg_score": -18.7,
  "top_k_avg_score": -16.1,
  "num_candidates": 50,
  "num_valid": 45,
  "failure_counts": {"syntax": 3, "timeout": 2},
  "timestamp": "2024-01-15T10:30:00"
}
```

**CSV æ ¼å¼** (ä¾¿äº Excel/Pandas):
```bash
cat artifacts/binpacking_demo_001/metrics.csv | head
```

### 5.2 åˆ†æå¯è§†åŒ–å›¾è¡¨

#### è¿›åŒ–æ›²çº¿ (`plots/evolution.png`)

æ˜¾ç¤º 4 æ¡æ›²çº¿:
1. **Best Score** (è“è‰²): æ¯ä»£æœ€ä½³åˆ†æ•°
2. **Avg Score** (æ©™è‰²): æ¯ä»£å¹³å‡åˆ†æ•°
3. **Top-K Avg** (ç»¿è‰²): Top-K å€™é€‰å¹³å‡åˆ†æ•°
4. **Valid Candidates** (çº¢è‰²): æœ‰æ•ˆå€™é€‰æ•°é‡

**å¥åº·æœç´¢çš„ç‰¹å¾**:
- Best Score æŒç»­ä¸Šå‡ (è¶Šæ¥è¶Šæ¥è¿‘ 0)
- Avg Score è·Ÿéšä¸Šå‡
- Valid Candidates ä¿æŒç¨³å®šæˆ–å¢åŠ 

**é—®é¢˜ä¿¡å·**:
- Best Score é•¿æ—¶é—´åœæ» â†’ å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜
- Avg Score è¿œä½äº Best Score â†’ å¤§éƒ¨åˆ†å€™é€‰è´¨é‡å·®
- Valid Candidates å¿«é€Ÿä¸‹é™ â†’ LLM ç”Ÿæˆå¤±è´¥ç‡é«˜

#### å¤±è´¥åˆ†å¸ƒ (`plots/failures.png`)

é¥¼å›¾æ˜¾ç¤ºå„ç±»å¤±è´¥çš„å æ¯”:
- **Syntax Error**: è¯­æ³•é”™è¯¯ â†’ Prompt éœ€è¦æ›´æ˜ç¡®çš„æ ¼å¼è¦æ±‚
- **Import Blocked**: å¯¼å…¥è¢«é˜»æ­¢ â†’ LLM å°è¯•ä½¿ç”¨ä¸å®‰å…¨çš„æ¨¡å—
- **Runtime Error**: è¿è¡Œæ—¶é”™è¯¯ â†’ é€»è¾‘é”™è¯¯æˆ–è¾¹ç•Œæ¡ä»¶æœªå¤„ç†
- **Timeout**: è¶…æ—¶ â†’ ç”Ÿæˆçš„ä»£ç æ•ˆç‡ä½

### 5.3 åˆ†æ SQLite æ•°æ®åº“

#### æŸ¥è¯¢æœ€ä½³å€™é€‰

```sql
-- æŸ¥è¯¢å†å²æœ€ä½³
SELECT id, score, generation, provider_id 
FROM candidates 
WHERE score IS NOT NULL 
ORDER BY score DESC 
LIMIT 10;

-- æŸ¥è¯¢ç‰¹å®šä»£æ•°çš„å€™é€‰
SELECT id, score 
FROM candidates 
WHERE generation = 10 
ORDER BY score DESC;

-- ç»Ÿè®¡æ¯ä»£æœ‰æ•ˆå€™é€‰æ•°
SELECT generation, COUNT(*) as count 
FROM candidates 
WHERE score IS NOT NULL 
GROUP BY generation;
```

#### æŸ¥è¯¢å¤±è´¥ç»Ÿè®¡

```sql
-- ç»Ÿè®¡å¤±è´¥ç±»å‹
SELECT 
  json_extract(metadata, '$.failure_type') as failure_type,
  COUNT(*) as count
FROM candidates
WHERE score IS NULL
GROUP BY failure_type;
```

### 5.4 æ¯”è¾ƒä¸åŒå®éªŒ

```bash
# å¯¹æ¯”ä¸¤ä¸ªå®éªŒçš„æœ€ä½³åˆ†æ•°
sqlite3 artifacts/exp1/candidates.db "SELECT MAX(score) as exp1_best FROM candidates;" &
sqlite3 artifacts/exp2/candidates.db "SELECT MAX(score) as exp2_best FROM candidates;"

# åˆå¹¶å¤šä¸ªå®éªŒçš„æŒ‡æ ‡
cat artifacts/exp1/metrics.csv > comparison.csv
tail -n +2 artifacts/exp2/metrics.csv >> comparison.csv
tail -n +2 artifacts/exp3/metrics.csv >> comparison.csv
```

---

## 6. é«˜çº§ç”¨æ³•

### 6.1 è‡ªå®šä¹‰é—®é¢˜

è¦æ·»åŠ æ–°é—®é¢˜ (å¦‚ TSP æ—…è¡Œå•†é—®é¢˜):

**æ­¥éª¤ 1**: å®ç°è¯„ä¼°å™¨

```python
# evaluator/tsp.py
from evaluator.base import BaseEvaluator, EvalResult, Candidate

class TSPEvaluator(BaseEvaluator):
    def __init__(self, num_cities: int, seed: int):
        self.num_cities = num_cities
        self.seed = seed
    
    def cheap_eval(self, candidate: Candidate) -> EvalResult:
        # å°è§„æ¨¡è¯„ä¼° (10 ä¸ªåŸå¸‚)
        score = self._evaluate_on_instances(candidate, n=10)
        return EvalResult(score=score, metadata={"fidelity": "cheap"})
    
    def full_eval(self, candidate: Candidate) -> EvalResult:
        # å®Œæ•´è¯„ä¼° (50 ä¸ªåŸå¸‚)
        score = self._evaluate_on_instances(candidate, n=50)
        return EvalResult(score=score, metadata={"fidelity": "full"})
```

**æ­¥éª¤ 2**: æ³¨å†Œè¯„ä¼°å™¨

```python
# experiments/runner.py
from evaluator.tsp import TSPEvaluator

def _create_evaluator(config: RunConfig) -> BaseEvaluator:
    if config.task_name == "bin_packing":
        return BinPackingEvaluator(...)
    elif config.task_name == "tsp":
        return TSPEvaluator(...)
    else:
        raise ValueError(f"Unknown task: {config.task_name}")
```

**æ­¥éª¤ 3**: åˆ›å»ºé…ç½®

```yaml
# configs/tsp.yaml
run_id: "tsp_experiment_001"
task_name: "tsp"
evaluator:
  num_cities: 50
  seed: 42
# ... å…¶ä»–é…ç½® ...
```

### 6.2 è‡ªå®šä¹‰ LLM æä¾›è€…

å®ç° `BaseLLMProvider` æ¥å£:

```python
# llm/custom_provider.py
from llm.base import BaseLLMProvider

class CustomProvider(BaseLLMProvider):
    def __init__(self, provider_id: str, api_key: str, model_name: str):
        self.provider_id = provider_id
        self.api_key = api_key
        self.model_name = model_name
    
    def generate(self, *, temperature: float, seed: int | None = None) -> str:
        # è°ƒç”¨è‡ªå®šä¹‰ API
        response = my_api_call(...)
        return response.code
    
    def mutate(self, *, parent_code: str, temperature: float, seed: int | None = None) -> str:
        # å˜å¼‚é€»è¾‘
        pass
    
    def refine(self, *, candidate_code: str, temperature: float, seed: int | None = None) -> str:
        # ç²¾ç‚¼é€»è¾‘
        pass
```

### 6.3 æ‰¹é‡è¿è¡Œå®éªŒ

```bash
#!/bin/bash
# run_experiments.sh

for seed in 42 43 44 45 46; do
  # åˆ›å»ºé…ç½®å‰¯æœ¬
  cp configs/binpacking.yaml configs/temp_${seed}.yaml
  
  # ä¿®æ”¹ run_id å’Œ seed
  sed -i "s/run_id: .*/run_id: \"binpacking_seed_${seed}\"/" configs/temp_${seed}.yaml
  sed -i "s/seed: .*/seed: ${seed}/" configs/temp_${seed}.yaml
  
  # è¿è¡Œå®éªŒ
  python -m experiments.cli run configs/temp_${seed}.yaml
  
  # æ¸…ç†ä¸´æ—¶é…ç½®
  rm configs/temp_${seed}.yaml
done

echo "All experiments complete!"
```

### 6.4 Python API (ç›´æ¥è°ƒç”¨)

```python
from experiments.runner import ExperimentRunner
from experiments.config import load_config

# åŠ è½½é…ç½®
config = load_config("configs/binpacking.yaml")

# è¿è¡Œå®éªŒ
runner = ExperimentRunner()
result = runner.run(config)

# è®¿é—®ç»“æœ
print(f"Best score: {result.best_candidate.score}")
print(f"Best code:\n{result.best_candidate.code}")
```

### 6.5 ä½¿ç”¨ OR-Library æ ‡å‡†æ•°æ®é›†

FunSearch-Lite å†…ç½®æ”¯æŒ OR-Library è£…ç®±é—®é¢˜æ ‡å‡†æµ‹è¯•é›†ï¼Œä¾¿äºä¸å­¦æœ¯æ–‡çŒ®å¯¹æ¯”ã€‚

#### å‘½ä»¤è¡Œä½¿ç”¨

```bash
# ä½¿ç”¨ OR-Library å°å‹æ•°æ®é›† (binpack1-4, 80ä¸ªå®ä¾‹)
python run.py -d orlib

# ä½¿ç”¨ OR-Library å¤§å‹æ•°æ®é›† (binpack5-8, 80ä¸ªå®ä¾‹)
python run.py -d orlib -s large

# å¿«é€Ÿæµ‹è¯• OR-Library
python run.py -d orlib -g 3 -p 3 -y
```

#### ç¼–ç¨‹æ–¹å¼åŠ è½½

```python
from evaluator.datasets import (
    load_orlib_dataset,
    load_orlib_small,
    load_orlib_large,
    generate_weibull_dataset,
)

# åŠ è½½å°å‹å®ä¾‹ (80 ä¸ªï¼Œç”¨äºå¿«é€Ÿæµ‹è¯•)
# åŒ…å« binpack1, binpack2, binpack5, binpack6
small = load_orlib_small()
print(f"Loaded {len(small)} small instances")

# åŠ è½½å¤§å‹å®ä¾‹ (80 ä¸ªï¼Œç”¨äºå®Œæ•´è¯„ä¼°)
# åŒ…å« binpack3, binpack4, binpack7, binpack8
large = load_orlib_large()
print(f"Loaded {len(large)} large instances")

# åŠ è½½å…¨éƒ¨å®ä¾‹ (160 ä¸ª)
all_data = load_orlib_dataset()
```

#### æŸ¥çœ‹å®ä¾‹è¯¦æƒ…

```python
for inst in small[:5]:
    print(f"{inst.name}: {inst.num_items} items, capacity={inst.capacity}, best_known={inst.best_known}")
```

è¾“å‡ºç¤ºä¾‹:
```
u120_00: 120 items, capacity=150, best_known=48
u120_01: 120 items, capacity=150, best_known=49
...
```

#### æŒ‰ç±»å‹ç­›é€‰å®ä¾‹

```python
# è·å– Uniform åˆ†å¸ƒå®ä¾‹ (u*)
uniform = small.get_uniform_instances()

# è·å– Triplet å®ä¾‹ (t*)
triplet = small.get_triplet_instances()

# æŒ‰ç‰©å“æ•°é‡ç­›é€‰
medium = all_data.filter_by_size(min_items=100, max_items=300)
```

#### ä½¿ç”¨ BenchmarkEvaluator

```python
from evaluator.bin_packing import BenchmarkEvaluator
from evaluator.datasets import load_orlib_small

# åˆ›å»ºåŸºå‡†è¯„ä¼°å™¨
dataset = load_orlib_small()
evaluator = BenchmarkEvaluator(dataset)

# è¯„ä¼°å€™é€‰
result = evaluator.evaluate(candidate)
print(f"Score: {result.score}")
print(f"Matching best known: {result.metadata['num_matching_best']}/{len(dataset)}")
```

#### ç”Ÿæˆè‡ªå®šä¹‰å®ä¾‹

```python
# ç”Ÿæˆ Weibull åˆ†å¸ƒçš„å®ä¾‹ (æ›´å…·æŒ‘æˆ˜æ€§)
weibull_dataset = generate_weibull_dataset(
    num_instances=50,
    num_items=200,
    capacity=100,
    seed=42
)
```

---

## 8. æ•…éšœæ’é™¤

### 8.1 å¸¸è§é—®é¢˜

#### é—®é¢˜ 1: `ModuleNotFoundError: No module named 'openai'`

**åŸå› **: ä½¿ç”¨ OpenAI/DeepSeek provider ä½†æœªå®‰è£… openai åŒ…

**è§£å†³æ–¹æ¡ˆ**:
```bash
pip install openai
# æˆ–ä½¿ç”¨ FakeProvider (ä¿®æ”¹é…ç½®æ–‡ä»¶ provider_type: "fake")
```

#### é—®é¢˜ 2: `api_key client option must be set`

**åŸå› **: æœªè®¾ç½® API å¯†é’¥ç¯å¢ƒå˜é‡

**è§£å†³æ–¹æ¡ˆ**:
```bash
# DeepSeek
export DEEPSEEK_API_KEY="sk-..."  # Linux/macOS
$env:DEEPSEEK_API_KEY = "sk-..."  # Windows PowerShell

# OpenAI
export OPENAI_API_KEY="sk-..."
```

#### é—®é¢˜ 3: æ‰€æœ‰å€™é€‰éƒ½å¤±è´¥ (num_valid = 0)

**åŸå› **: 
- Prompt ä¸æ¸…æ™°å¯¼è‡´ LLM ç”Ÿæˆæ— æ•ˆä»£ç 
- æ²™ç®±é™åˆ¶è¿‡ä¸¥
- è¶…æ—¶æ—¶é—´è¿‡çŸ­

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥å¤±è´¥ç±»å‹
sqlite3 artifacts/<run_id>/candidates.db \
  "SELECT json_extract(metadata, '$.error_message') FROM candidates LIMIT 10;"

# æ ¹æ®é”™è¯¯ç±»å‹è°ƒæ•´:
# - è¯­æ³•é”™è¯¯ â†’ ä¼˜åŒ– Prompt
# - è¶…æ—¶ â†’ å¢åŠ  timeout_seconds
# - å¯¼å…¥è¢«é˜»æ­¢ â†’ æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ å®‰å…¨æ¨¡å—
```

#### é—®é¢˜ 4: Best Score åœæ»ä¸å‰

**åŸå› **: é™·å…¥å±€éƒ¨æœ€ä¼˜

**è§£å†³æ–¹æ¡ˆ**:
- å¢åŠ ç§ç¾¤å¤šæ ·æ€§: `population_size: 100`
- å¢åŠ å²›å±¿æ•°é‡: `num_islands: 5`
- è°ƒæ•´æ¸©åº¦: `temperature: 1.0` (æ›´é«˜ = æ›´æ¢ç´¢æ€§)
- ä½¿ç”¨æ›´å¼ºå¤§çš„æ¨¡å‹

#### é—®é¢˜ 5: Windows ä¸Šèµ„æºé™åˆ¶ä¸ç”Ÿæ•ˆ

**åŸå› **: Windows ä¸æ”¯æŒ `resource.setrlimit()`

**è§£å†³æ–¹æ¡ˆ**: è¿™æ˜¯é¢„æœŸè¡Œä¸ºï¼Œæ²™ç®±ä¼šä¼˜é›…é™çº§ã€‚ä»…è¶…æ—¶é™åˆ¶æœ‰æ•ˆã€‚

### 8.2 è°ƒè¯•æ¨¡å¼

å¯ç”¨è¯¦ç»†æ—¥å¿—:

```python
# åœ¨ runner.py é¡¶éƒ¨æ·»åŠ 
import logging
logging.basicConfig(level=logging.DEBUG)
```

### 8.3 æ€§èƒ½ä¼˜åŒ–

**å¦‚æœå®éªŒè¿è¡Œå¤ªæ…¢**:

1. **å‡å°‘è¯„ä¼°æˆæœ¬**:
   ```yaml
   top_k_for_full_eval: 5  # å‡å°‘å®Œæ•´è¯„ä¼°æ•°é‡
   ```

2. **å‡å°‘å€™é€‰æ•°é‡**:
   ```yaml
   population_size: 15  # å‡å°‘æ¯ä»£å€™é€‰æ•°
   ```

3. **ä½¿ç”¨ LLM ç¼“å­˜**:
   - ç¼“å­˜è‡ªåŠ¨å¯ç”¨ï¼Œé‡å¤å®éªŒæ—¶ä¼šå‘½ä¸­ç¼“å­˜

4. **é¢„è®¡æ—¶é—´ä¼°ç®—**:
   - å®éªŒè¿è¡Œæ—¶ä¼šæ˜¾ç¤º tqdm è¿›åº¦æ¡å’Œé¢„è®¡æ€»æ—¶é—´
   - æ€»æ—¶é—´ â‰ˆ max_generations Ã— num_islands Ã— population_size Ã— å¹³å‡APIå“åº”æ—¶é—´

---

## é™„å½•

### A. é…ç½®æ–‡ä»¶æ¨¡æ¿

#### FakeProvider æ¨¡æ¿ (æµ‹è¯•ç”¨)

```yaml
# configs/template_fake.yaml
run_id: "my_experiment_001"
seed: 42
max_generations: 20
population_size: 50
num_islands: 3
top_k_for_full_eval: 10

task_name: "bin_packing"
evaluator:
  capacity: 100
  seed: 42

llm_providers:
  - provider_id: "fake_gen"
    provider_type: "fake"
    model_name: "fake-model"
    max_retries: 3
    timeout_seconds: 30

generator_provider_id: "fake_gen"
refiner_provider_id: "fake_gen"

artifact_dir: "artifacts"
save_interval: 5
```

#### DeepSeek æ¨¡æ¿ (æ¨è)

```yaml
# configs/template_deepseek.yaml
run_id: "my_experiment_001"
seed: 42
max_generations: 50
population_size: 15
num_islands: 3
top_k_for_full_eval: 5

task_name: "bin_packing"
evaluator:
  capacity: 100
  seed: 42

llm_providers:
  - provider_id: "deepseek_gen"
    provider_type: "deepseek"
    model_name: "deepseek-chat"
    base_url: "https://api.deepseek.com"
    max_retries: 3
    timeout_seconds: 60
    temperature: 1.0
    max_tokens: 2000

generator_provider_id: "deepseek_gen"
refiner_provider_id: "deepseek_gen"

artifact_dir: "artifacts"
save_interval: 5
```

#### OpenAI æ¨¡æ¿

```yaml
# configs/template_openai.yaml
run_id: "my_experiment_001"
seed: 42
max_generations: 50
population_size: 30
num_islands: 3
top_k_for_full_eval: 10

task_name: "bin_packing"
evaluator:
  capacity: 100
  seed: 42

llm_providers:
  - provider_id: "openai_gen"
    provider_type: "openai"
    model_name: "gpt-3.5-turbo"
    temperature: 0.8
    max_tokens: 2000
    max_retries: 3
    timeout_seconds: 30

generator_provider_id: "openai_gen"
refiner_provider_id: "openai_gen"

artifact_dir: "artifacts"
save_interval: 10
```

### B. æœ‰ç”¨çš„è„šæœ¬

**å¯¼å‡ºæ‰€æœ‰å®éªŒçš„æœ€ä½³åˆ†æ•°**:
```bash
#!/bin/bash
echo "Run ID,Best Score"
for dir in artifacts/*/; do
  run_id=$(basename $dir)
  best_score=$(sqlite3 "${dir}candidates.db" "SELECT MAX(score) FROM candidates;")
  echo "${run_id},${best_score}"
done > all_results.csv
```

**æ¸…ç†å¤±è´¥çš„å®éªŒ**:
```bash
#!/bin/bash
for dir in artifacts/*/; do
  if [ ! -f "${dir}best_candidate.py" ]; then
    echo "Removing incomplete run: $(basename $dir)"
    rm -rf "$dir"
  fi
done
```

### C. æ”¯æŒçš„ LLM æä¾›è€…

| æä¾›è€… | provider_type | ç¯å¢ƒå˜é‡ | è¯´æ˜ |
|--------|---------------|----------|------|
| DeepSeek | `deepseek` | `DEEPSEEK_API_KEY` | æ¨èï¼Œæ€§ä»·æ¯”é«˜ï¼Œéœ€è¦è®¾ç½® base_url |
| OpenAI | `openai` | `OPENAI_API_KEY` | GPT-3.5/GPT-4 |
| FakeProvider | `fake` | æ— éœ€ | æµ‹è¯•ç”¨ï¼Œç¡®å®šæ€§è¾“å‡º |

---

## ä¸‹ä¸€æ­¥

- é˜…è¯» [ARCHITECTURE.md](ARCHITECTURE.md) äº†è§£ç³»ç»Ÿè®¾è®¡
- é˜…è¯» [INNOVATION_POINTS.md](INNOVATION_POINTS.md) äº†è§£ä¸‰ä¸ªåˆ›æ–°ç‚¹
- é˜…è¯» [SANDBOX_LIMITATIONS.md](SANDBOX_LIMITATIONS.md) äº†è§£å®‰å…¨é™åˆ¶
- æŸ¥çœ‹ `tests/` ç›®å½•äº†è§£æµ‹è¯•ç”¨ä¾‹
- è¿è¡Œä½ çš„ç¬¬ä¸€ä¸ªå®éªŒï¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥:
1. æ˜¯å¦æ­£ç¡®å®‰è£…ä¾èµ– (`pip install -e .`)
2. æ˜¯å¦é€šè¿‡æµ‹è¯• (`pytest tests/ -v`)
3. æ˜¯å¦æ­£ç¡®é…ç½® YAML æ–‡ä»¶
4. æ˜¯å¦è®¾ç½®äº†ç¯å¢ƒå˜é‡ (DEEPSEEK_API_KEY æˆ– OPENAI_API_KEY)
